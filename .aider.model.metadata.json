{
    "openrouter/openai/gpt-4o": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 0.000005,
        "output_cost_per_token": 0.000015,
        "litellm_provider": "openrouter",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true
    },
    "github/gpt-4o": {
        "max_tokens": 8000,
        "max_input_tokens": 8000,
        "max_output_tokens": 4000,
        "input_cost_per_token": 0.000000,
        "output_cost_per_token": 0.000000,
        "litellm_provider": "github",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true
    },
    "openrouter/openai/gpt-4o-mini": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 0.00000015,
        "output_cost_per_token": 0.00000060,
        "cache_read_input_token_cost": 0.000000075,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true,
        "supports_prompt_caching": true
    },
    "github/gpt-4o-mini": {
        "max_tokens": 8000,
        "max_input_tokens": 8000,
        "max_output_tokens": 4000,
        "input_cost_per_token": 0.00000015,
        "output_cost_per_token": 0.00000060,
        "cache_read_input_token_cost": 0.000000075,
        "litellm_provider": "github",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true,
        "supports_prompt_caching": true
    },
    "openrouter/anthropic/claude-3.5-sonnet": {
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 0.000003,
        "output_cost_per_token": 0.000015,
        "litellm_provider": "openrouter",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "github/claude-3.5-sonnet": {
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 0.000003,
        "output_cost_per_token": 0.000015,
        "litellm_provider": "openrouter",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "openrouter/deepseek/deepseek-coder": {
        "max_tokens": 65536,
        "max_input_tokens": 65536,
        "max_output_tokens": 8192,
        "input_cost_per_token": 0.00000014,
        "output_cost_per_token": 0.00000028,
        "litellm_provider": "openrouter",
        "mode": "chat"
    },
    "openrouter/deepseek/deepseek-chat": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 0.00000014,
        "output_cost_per_token": 0.00000028,
        "litellm_provider": "openrouter",
        "supports_function_calling": true,
        "mode": "chat"
    },
    "openrouter/deepseek/deepseek-chat-v3-0324:free": {
        "max_tokens": 163840,
        "max_input_tokens": 163840,
        "max_output_tokens": 163840,
        "input_cost_per_token": 0.00000000,
        "output_cost_per_token": 0.00000000,
        "litellm_provider": "openrouter",
        "supports_function_calling": true,
        "mode": "chat"
    },
    "openrouter/deepseek/deepseek-r1": {
        "max_tokens": 163840,
        "max_input_tokens": 163840,
        "max_output_tokens": 163840,
        "input_cost_per_token": 0.00000055,
        "output_cost_per_token": 0.00000219,
        "litellm_provider": "openrouter",
        "supports_function_calling": true,
        "mode": "chat"
    },
    "openrouter/deepseek/deepseek-r1-0528:free": {
        "max_tokens": 163840,
        "max_input_tokens": 163840,
        "max_output_tokens": 163840,
        "input_cost_per_token": 0.00000000,
        "output_cost_per_token": 0.00000000,
        "litellm_provider": "openrouter",
        "supports_function_calling": true,
        "mode": "chat"
    },
    "openrouter/meta-llama/llama-3.1-8b-instruct": {
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 0.0000006,
        "output_cost_per_token": 0.0000006,
        "litellm_provider": "openrouter",
        "mode": "chat",
        "supports_function_calling": true
    },
    "openrouter/meta-llama/llama-3.2-11b-vision-instruct": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 0.0000006,
        "output_cost_per_token": 0.0000006,
        "litellm_provider": "openrouter",
        "mode": "chat",
        "supports_function_calling": true
    },
    "openrouter/qwen/qwen-2.5-coder-32b-instruct": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 0.00000018,
        "output_cost_per_token": 0.00000018,
        "litellm_provider": "openrouter",
        "mode": "chat"
    },
    "openrouter/google/gemini-2.5-pro-preview": {
        "max_tokens": 1048576,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "input_cost_per_token": 0.00000125,
        "output_cost_per_token": 0.00001000,
        "litellm_provider": "openrouter",
        "mode": "chat"
    }
}
